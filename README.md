# Review Paper
**리뷰한 논문 정리**  
X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection (Usenix 2023) [x-adv.pptx](https://github.com/user-attachments/files/19964074/x-adv.pptx)  
AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE (ICLR 2021) [Vit 논문 정리.pptx](https://github.com/user-attachments/files/19964073/Vit.pptx)   
Attention is all you need [Transformer.pptx](https://github.com/user-attachments/files/19964072/Transformer.pptx)  
Synthesizing Robust Adversarial Examples (ICLR 2018) [Synthesizing Robust Adversarial Examples.pptx](https://github.com/user-attachments/files/19964071/Synthesizing.Robust.Adversarial.Examples.pptx)  
Sponge Examples: Energy-Latency Attacks on Neural Networks (Euro S&P 2021) [Sponge Example.pptx](https://github.com/user-attachments/files/19964070/Sponge.Example.pptx)  
SafetyBench: Evaluating the Safety of Large Language Models [Saftey Bench.pptx](https://github.com/user-attachments/files/19964069/Saftey.Bench.pptx)  
One Pixel Adversarial Attacks via Sketched Programs (PLDI 2023) [OPPSLA.pptx](https://github.com/user-attachments/files/19964068/OPPSLA.pptx)  
One pixel attack for fooling deep neural networks [One pixel attack.pptx](https://github.com/user-attachments/files/19964067/One.pixel.attack.pptx)  
Making an Invisibility Cloak- Real World Adversarial Attacks on Object Detectors(ECCV 2020) [Making an Invisibility Cloak- Real World Adversarial Attacks on Object Detectors.pptx](https://github.com/user-attachments/files/19964063/Making.an.Invisibility.Cloak-.Real.World.Adversarial.Attacks.on.Object.Detectors.pptx)  
GAN 기반 은닉 적대적 패치 생성 기법에 관한 연구 [GAN 기반 은닉 적대적 패치 생성 기법에 관한 연구.pptx](https://github.com/user-attachments/files/19964060/GAN.pptx)  
Explaining and Harnessing Adversarial Examples [Explaining and Harnessing Adversarial Examples.pptx](https://github.com/user-attachments/files/19964056/Explaining.and.Harnessing.Adversarial.Examples.pptx)  
DPatch: An Adversarial Patch Attack on Object Detectors [Dpatch.pptx](https://github.com/user-attachments/files/19964054/Dpatch.pptx)  
DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks (CVPR 2016) [Deepfool.pptx](https://github.com/user-attachments/files/19964050/Deepfool.pptx)  
Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt [BAP.pptx](https://github.com/user-attachments/files/19964049/BAP.pptx)  
Assistive Signals for Deep Neural Network Classiﬁers (CVPR 2021) [Assistive Signals for Deep Neural Network Classiﬁers.pptx](https://github.com/user-attachments/files/19964048/Assistive.Signals.for.Deep.Neural.Network.Classi.ers.pptx)  
Adversarial Patch [Adversarial Patch.pptx](https://github.com/user-attachments/files/19964046/Adversarial.Patch.pptx)  
Universal and Transferable Adversarial Attacks on Aligned Language Models [AdvBench.pptx](https://github.com/user-attachments/files/19964044/AdvBench.pptx)  


# Paper Implementation  
**구현한 논문들**  
- Transformer (Attention is all you need)
- X-ADV
- Synthesizing Robust Adversarial Examples
